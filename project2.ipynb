{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Import Libraries \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 13:06:05.556678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 13:06:05.770823: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-30 13:06:05.774179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-30 13:06:05.774191: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 13:06:10.161168: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-30 13:06:10.161310: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-30 13:06:10.161319: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "# import mlrose\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"heart_cleveland_upload.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   69    1   0       160   234    1        2      131      0      0.1      1   \n",
      "1   69    0   0       140   239    0        0      151      0      1.8      0   \n",
      "2   66    0   0       150   226    0        0      114      0      2.6      2   \n",
      "3   65    1   0       138   282    1        2      174      0      1.4      1   \n",
      "4   64    1   0       110   211    0        2      144      1      1.8      1   \n",
      "\n",
      "   ca  thal  condition  \n",
      "0   1     0          0  \n",
      "1   2     0          0  \n",
      "2   0     0          0  \n",
      "3   1     0          1  \n",
      "4   0     0          0  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preprocess\n",
    "\n",
    "Since the dataset contains only numerical features, we need to scale the numerical features using StandardScaler from sklearn library. We also need to split the dataset into input features (X) and output feature (y), where y is the \"condition\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "num_cols = data.select_dtypes(include=\"number\").columns.tolist()\n",
    "scaler = StandardScaler()\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "X = data.drop(\"condition\", axis=1)\n",
    "y = data[\"condition\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Define the fitness function for neural network weights\n",
    "\n",
    "We can experiment with different architectures and hyperparameters. Here we use a neural network architecture with 3 hidden layers, each with 64 neurons, and dropout regularization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def nn_fitness_function(weights):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.set_weights(weights)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    score = model.evaluate(X_train, y_train, verbose=0)\n",
    "    return -score[1]  # minimize the negative accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Define the optimization problems for the different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "fitness_functions = [\n",
    "    nn_fitness_function,\n",
    "    lambda x: -(x[0]**2 + x[1]**2),\n",
    "    lambda x: -abs(x[0] * np.sin(x[0]) + 0.1 * x[0])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Define the search spaces for the different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "search_spaces = [\n",
    "    np.array([-5, 5], dtype=np.float64),\n",
    "    np.array([-5, 5], dtype=np.float64),\n",
    "    np.array([-5, 5], dtype=np.float64)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlrose' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_135888/653339194.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     {\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"RHC\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;34m\"function\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmlrose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_hill_climb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m\"kwargs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"max_attempts\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"restarts\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m\"fitness_function\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfitness_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlrose' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the algorithms\n",
    "algorithms = [\n",
    "    {\n",
    "        \"name\": \"RHC\",\n",
    "        \"function\": mlrose.random_hill_climb,\n",
    "        \"kwargs\": {\"max_attempts\": 100, \"restarts\": 10},\n",
    "        \"fitness_function\": fitness_functions[1],\n",
    "        \"search_space\": search_spaces[1]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SA\",\n",
    "        \"function\": mlrose.simulated_annealing,\n",
    "        \"kwargs\": {\"max_attempts\": 100, \"schedule\": mlrose.ExpDecay()},\n",
    "        \"fitness_function\": fitness_functions[2],\n",
    "        \"search_space\": search_spaces[2]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"GA\",\n",
    "        \"function\": mlrose.genetic_alg,\n",
    "        \"kwargs\": {\"pop_size\": 200, \"mutation_prob\": 0.1},\n",
    "        \"fitness_function\": fitness_functions[0],\n",
    "        \"search_space\": None  # No search space needed for GA\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Random Search\",\n",
    "        \"function\": mlrose.random_search,\n",
    "        \"kwargs\": {\"max_attempts\": 100, \"max_iters\": 100, \"restarts\": 0},\n",
    "        \"fitness_function\": fitness_functions[3],\n",
    "        \"search_space\": {\n",
    "            \"layer1\": np.linspace(16, 128, num=7, dtype=np.int),\n",
    "            \"layer2\": np.linspace(16, 128, num=7, dtype=np.int),\n",
    "            \"layer3\": np.linspace(16, 128, num=7, dtype=np.int),\n",
    "            \"dropout\": np.linspace(0.1, 0.5, num=5),\n",
    "            \"lr\": np.logspace(-4, -1, num=4),\n",
    "            \"batch_size\": [16, 32, 64]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Randomized Hill Climbing\",\n",
    "        \"function\": mlrose.random_hill_climb,\n",
    "        \"kwargs\": {\"max_attempts\": 100, \"restarts\": 10},\n",
    "        \"fitness_function\": fitness_functions[1],\n",
    "        \"search_space\": search_spaces[1],\n",
    "        \"random_state\": 42\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Simulated Annealing\",\n",
    "        \"function\": mlrose.simulated_annealing,\n",
    "        \"kwargs\": {\"max_attempts\": 100, \"schedule\": mlrose.ExpDecay()},\n",
    "        \"fitness_function\": fitness_functions[2],\n",
    "        \"search_space\": search_spaces[2],\n",
    "        \"random_state\": 42\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Genetic Algorithm\",\n",
    "        \"function\": mlrose.genetic_alg,\n",
    "        \"kwargs\": {\"pop_size\": 200, \"mutation_prob\": 0.1},\n",
    "        \"fitness_function\": fitness_functions[0],\n",
    "        \"search_space\": None,  # No search space needed for GA\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlrose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_135888/2751267530.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmlrose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_algorithms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlrose'"
     ]
    }
   ],
   "source": [
    "import mlrose\n",
    "import numpy as np\n",
    "\n",
    "def run_algorithms(X_train, algorithms):\n",
    "    results = []\n",
    "\n",
    "    for algo in algorithms:\n",
    "        if algo[\"search_space\"] is None:\n",
    "            problem = mlrose.DiscreteOpt(length=len(X_train.columns), fitness_fn=algo[\"fitness_function\"])\n",
    "        else:\n",
    "            problem = mlrose.DiscreteOpt(length=len(X_train.columns), fitness_fn=algo[\"fitness_function\"], \n",
    "                                         maximize=False, max_val=max(algo[\"search_space\"]))\n",
    "        if algo[\"name\"] == \"Random Search\":\n",
    "            init_state = None\n",
    "            schedule = mlrose.ExpDecay()\n",
    "            best_state, best_fitness = mlrose.random_search(problem, \n",
    "                                                            max_attempts=algo[\"kwargs\"][\"max_attempts\"],\n",
    "                                                            max_iters=algo[\"kwargs\"][\"max_iters\"],\n",
    "                                                            restarts=algo[\"kwargs\"][\"restarts\"],\n",
    "                                                            curve=False,\n",
    "                                                            random_state=42)\n",
    "        else:\n",
    "            best_state, best_fitness, _ = mlrose.optimize(problem,\n",
    "                                                          algorithm=algo[\"function\"],\n",
    "                                                          max_attempts=algo[\"kwargs\"][\"max_attempts\"],\n",
    "                                                          max_iters=np.inf,\n",
    "                                                          restarts=algo[\"kwargs\"].get(\"restarts\", 0),\n",
    "                                                          init_state=algo.get(\"init_state\", None),\n",
    "                                                          schedule=algo.get(\"schedule\", None),\n",
    "                                                          mutation_prob=algo.get(\"mutation_prob\", None),\n",
    "                                                          pop_size=algo.get(\"pop_size\", None),\n",
    "                                                          curve=False,\n",
    "                                                          random_state=42)\n",
    "\n",
    "        results.append({\n",
    "            \"name\": algo[\"name\"],\n",
    "            \"best_state\": best_state,\n",
    "            \"best_fitness\": best_fitness\n",
    "        })\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}